% -*- Mode: noweb; noweb-default-code-mode: R-mode; -*-
%\SweaveUTF8
\documentclass[11pt]{article}
\usepackage{graphicx}
%% \usepackage{Sweave}
\usepackage[utf8]{inputenc}
%% \usepackage{germanU}
%%- \usepackage[noae]{Sweave}
\usepackage[a4paper]{geometry}  %% , text={14.5cm,22cm}
\usepackage{color} %uncomment BF
\usepackage{booktabs} % nice tables with \toprule \middlerule \bottomrule
\usepackage{amsmath} % for align
% \usepackage{wasysym} % for promille sign
% \usepackage{amssymb}
% \usepackage[textfont=it,font=small,labelfont=it]{caption}
\interfootnotelinepenalty=10000 % prevent LaTex from two-sided footnotes
\usepackage{relevance-descr}
\usepackage{parskip}
%\VignetteEngine{knitr::knitr}
%\VignetteDepends{relevance}
%\VignetteIndexEntry{'Package relevance for calculating Relevance and Significance Measures'}
\addtolength{\textwidth}{2.5cm}%%--- 15.0 + 2.5 = 17.5
\addtolength{\oddsidemargin}{-1.04cm}

%% ================================================================

\begin{document}
%% \bibliography{regrbib}
%% \SweaveOpts{concordance=TRUE,width=9,height=6, echo=false}
\setkeys{Gin}{width=0.95\textwidth}
\baselineskip 15pt

\title{\vspace*{-10mm}
Package \T{relevance} for calculating Relevance and Significance Measures}
\author{Werner A. Stahel, ETH Zurich}
\maketitle

\begin{abstract}\noindent
  Relevance and significance measures are characteristics of statistical
  results that lead to an informative inference. 
  The relevance measure is based on the specification of a threshold of 
  relevance and indicates whether a result is to be called 
  (scientifically) relevant, negligible, or ambiguous.
  
  The package \T{relevance} calculates these measures for a simple
  comparison of two samples as well as for many regression models 
  and provides a suitable prinitng method.

\end{abstract}

<<preliminary, echo=F, message=F>>=
## library(plgraphics, lib.loc="/u/stahel/R/regdevelop/pkg/plgraphics.Rcheck")
library(relevance) ##, lib.loc="/u/stahel/R/regdevelop/pkg/relevance.Rcheck")
## options(warn=1)
@ 
\section{Introduction}

This package implements the concepts of relevance and significance as
introduced by Stahel (2021). 
They allow for meaningful statistical inference beyond the questionable 
common practice of Null Hypothesis Significance Testing that is in turn
often reduced to citing a p-value.

\Tit{The problem.}
Consider the problem of estimating an \emph{effect}, for example,
a mean (an expected value), a difference of means between two samples, 
or a regression coefficient.

\Tit{The Zero Hypothesis Testing Paradox.}
In common practice, statistical inference is reduced to testing whether
the effect might be zero, and the respective p-value is provided as the
result. This has been widely criticized as being too simple an answer.
In fact, it relates to a question that is not scientifically
meaningful as seen by the ``Zero Hypothesis Testing Paradox'':
When a study is undertaken to find a difference between samples or some 
influence between variables, the
\emph{true} effect---e.g., the difference between the expected values of
two samples---will never be precisely zero. 
Therefore, the strawman hypothesis of zero true effect could
in almost all reasonable applications be rejected if one had the
patience and resources to obtain enough observations.
Thus, the question that is answered mutates to:
``Did we produce sufficiently many observations to prove
the (alternative) hypothesis that was true on an apriori basis?''
This does not seem to be a fascinating task.

\Tit{Relevance.}
The scientifically meaningful question is whether the effect is
\emph{relevant}, and this needs the specification of a 
\emph{relevance threshold} $\zeta$.
The \emph{relevance measure} is defined as the ratio of the 
estimated effect $\wh\eff$ and the threshold,
\[
  \Rl e = \wh\eff\big/\zeta
  \;.
\]
The confidence interval for the effect translates to the interval
for the relevance with limits

\Quad  $\Rl s$: ``secured relevance'': the lower end;

\Quad  $\Rl p$: ``potential relevance'': the upper end.

\Tit{Significance.}
Let us return to the problem of testing a null hypothesis,
and even to the case of testing $\eff=0$.
The common way to express the result is to provide the p-value.
However, this measure is more difficult to interpret than needed.
We have been trained to compare it to the ``level'' of $5\%$ and
celebrate if it is \emph{below}. It is thus a measure of lack of
significance, and the desired range is just $0\le p\le 0.05$.
We also developed the skill of judging the values in this range
as to ``how significant'' the result is.

In ``ancient'' times, before the computer produced p-values readily,
statisticians examined the test statistics and then compared them to
corresponding ``critical values.'' In the widespread
case that the t test was concerned, they used the t statistic as an
informal quantitative measure of significance of an effect by comparing it 
to the number 2, which is approximately the critical value
for moderate to large numbers of degrees of freedom.

The significance measure $\Sg0$ picks up this idea, but standardizes
with the actual critical value,
\[
  \Sg0 = \wh\eff \big/ (q\;\mbox{se})
\;,
\]
where $\mbox{se}$ is the standard error of $\wh\eff$ and $q$ is the
appropriate quantile.
Then, the test rejects the null hypothesis $\eff=0$ whenever $|\Sg0|>1$,
and $\Sg0$ is proportional to the estimated effect.
It is thus interpretable in a quantitative way as a measure of significance
without special training.

\Tit{Regression models.}
In regression, there are different ways to characterize the
relevance of the individual terms of the model.
Firstly, for scalar predictors, the coefficient is the obvious
effect to examine. 
An alternative is the effect of dropping the predictor from the model, 
which also reflects its collinearity with the other predictors and
generalizes to the case where the predictor is a factor 
(or another term with more than one degree of freedom),
thus also encompassing \emph{analysis of variance.}
A third aspect is the relevance of the term for prediction of the 
target variable.
For details, see Stahel (2021).

\Tit{Choice of Relevance Thresholds.}
As noted above, the new relevance measure presupposes the choice of a 
relevance threshold. 
Ideally, this threshold is determined for each scientific question
on the basis of specific knowledge about the phenomenon that is modeled.
Since this is a severe burden, Stahel (2021) proposes some conventions 
for most common statistical models that may be used as a standard, 
like the testing level of $5\%$ is for classical null hypothesis testing.
(Note that the latter choice also affects the relevance measures 
$\Rl s$ and $\Rl p$.)

The convention includes, as a first step, to determine an appropriate
standardized effect or ``effect size'' for the model at hand,
and then setting a relevance threshold for it.
Table~\ref{tab:recommendation}, taken from Stahel (2021) collects the
proposed effect sizes and thresholds.
The symbol $\%\ell$ indicates that the threshold refers to a log scale.
For small effects on the log scale, these transform to the respective
percentages in the original scale.

\begin{table}[hh]
  \caption{Models, recommended effect scales and relevance thresholds
  \protect\linebreak} %% ???
  \label{tab:recommendation}
  \centering
  \begin{tabular}{|l|c|c|c|}
    Problem&Basic model
      &Effect $\eff=g\fn{\theta}$&Rel.\ thresh.\ $\zeta$ \Hline{&&&}
    One, or two & $\N\fn{\mu,\sigma^2}$ & $\mu/\sigma$ & $10\,\%$ \\[-2pt]
    \Quad paired samples &&&\Hline{&&&} %\\[3pt]
    Two independent & $\N\fn{\mu_k,\sigma^2}$ & $d=(\mu_1-\mu_0)/\sigma$
                    & $20\,\%$ \\
    \Quad samples&&$\eff=(\mu_1-\mu_0)\sqrt{\nu_0\nu_1}/\sigma$& $10\,\%$ \Hline{&&&} %\\[5pt]
    Regression  & $Y_i=\alpha+\vc x_i\tr\vc\beta+\eps_i$ &&\\
     & $\eps_i\sim\N\fn{0,\sigma^2}$ &&\\[-8pt]
    \Quad coefficients &  & $\vc\beta_j \sqrt{\MS X\sups j}\big/\sigma$&$10\,\%$ \\
    \Quad prediction error &&$-\oneover2\log\fn{1-R^2}$ &$0.5\,\%\ell$ or
                                                          $5\,\%\ell$ \Hline{&&&} %\\[5pt]
    Logistic regression %, coefficients
           & $g\fn{Y_i=1}= \alpha+\vc x_i\tr\vc\beta$
      & $\vc\beta_j 0.6\,\sqrt{\MS X\sups j}\big/\sqrt\phi$ & $10\,\%\ell$\Hline{&&&} %\\[8pt] 
    Relative
    Difference & $\log\fn Y\sim
                          \N\fn{\mu_k,\sigma^2}$ & $\log\fn{\mu_1/\mu_0}$&$10\,\%\ell$\Hline{&&&} %\\[5pt]
    Proportion  & $\Bin\fn{n, p}$ &  $\log\fn{p/(1-p)}$ & $33\,\%\ell$ or $10\,\%\ell$\Hline{&&&} %\\[5pt]
%%-     Simple regression  & $Y_i=\alpha+\beta x_i+E$ & \\
%%-            & $ E\sim\N\fn{0,\sigma^2}$
%%-       & $\beta \sqrt{\MS X}/\sigma$&$10\,\%$ \\[5pt]
    Correlation
           & $\vc Y\sim
             \N_2\fn{\vc\mu, \Sig}$ &&\\
           & $\rho=\Sig_{12}/\sqrt{\Sig_{11}\Sig_{22}}$& $\oneover2
                                      \log\fn{(1+\rho)/(1-\rho)}$&$10\,\%\ell$
      %% &better: $-\oneover2\log\fn{1-\rho^2}$&$0.5\,\%\ell$ or $5\,\%\ell$\\[5pt]
    \\[5pt]\hline
  \end{tabular}
\end{table}

In the package, the thresholds used by default are given by 
<<rlvthres>>=
getOption("rlv.threshold")
@ 
and can be modified by setting these options again, see below.

%%- \Tit{Package \T{regr}.}
%%- For regression models, the new measures are obtained by calling
%%- \T{ciSgRl}.
%%- It is programmed to 

\section{Functions}
\label{sec:functions}

\Tit{Function \T{twosamples}.}
This function provides inference for the comparison of two samples, paired
or unpaired, and also for a single sample.
Its call mimics \T{t.test}.

<<twosamples>>=
  t.test(sleep[sleep$group == 1, "extra"], sleep[sleep$group == 2, "extra"])
(r.sleep <- 
   twosamples(sleep[sleep$group == 1, "extra"], sleep[sleep$group == 2, "extra"])
)
@ 
The output shows the estimated effect and its confidence interval together
with the relevance measures. 
The estimated relevance $\Rl e$ compares the standardized effect
$\wb X/S =$\Sexpr{r.sleep["effect"]}/\Sexpr{r.sleep["se"]*sqrt(18)},
where $S$ is the estimated standard deviation of the observations,
to its relevance threshold $0.1$.
The classical results, t test statistic, standard error and p value 
are also calculated, but not shown with the default printing options.
They can also be obtained, as well as the significance \T{Sig0},
by changing options (for details, see Section \ref{sec:options}),
<<sleep2>>=
t.oldopt <- options(show.inference = "classical")
r.sleep
options(t.oldopt)  ##  restore the old options
@ 

\Tit{Function \T{termtable}.}
For regression models with a linear predictor, the basic function is
\T{termtable}.
For each term reflecting a scalar predictor, its result contains the 
ordinary and standardized coefficient, their confidence intervals,
significance against 0, p-value, and relevances.
For all types of terms, with one or more degrees of freedom, it adds
the relevances %and
for dropping the term and for its contribution to prediction.

Since this leads to 22 columns, the print method selects columns
according to \T{getOption("show")}.

<<termtable>>=
  data(swiss, package="datasets")
  rr <- lm(Fertility ~ . , data = swiss)
  rt <- termtable(rr)
  rt
  names(rt)
  if(interactive()) { ## too much avoidable output for the vignette
    str(rt)  
    print(data.frame(rt)) ## or  print(rt, show="all")
    ## This avoids selection and preparation of columns 
    ## by 'print.inference'. It produces an extensive output.
  }
@ 
\Tit{Plot.}
\T{inference} objects relate to a specific plotting method that shows 
the confidence interval(s) on the relevance scale. Here is the example.
<<plot.inference, fig.height=5, fig.width=9>>=
plot(rt)
@

\Tit{Function \T{termeffects}.}
For terms with more than one degree of freedom, notably for factors with
more than two levels,
the function \T{termeffects} calculates effects of levels and 
respective inference measures. 
As seen here, there are \T{print} and \T{plot} methods for the resulting objects.
<<termeffects, fig.width=9, fig.height=6>>=
data(d.blast)
r.blast <-
  lm(log10(tremor)~location+log10(distance)+log10(charge), data=d.blast)
(rte <- termeffects(r.blast))
print(rte, show=c("classical","coefRls","coefRls.symbol"), single=TRUE)

plot(termeffects(r.blast), single=TRUE)  ## plot all effects
@ 


\section{Options}
\label{sec:options}

The package works with some specific options, see \T{relevance.options}.
The more important ones are the following. 
\begin{itemize}
\item \T{rlv.threshold}:
vector of relevance thresholds for 
  \begin{itemize}
  \item \T{stand}: an effect standardized by a standard deviation, 
    like Cohen's d for two samples,
  \item \T{rel}: a relative effect, that is, a change in a prameter 
    expressed as a percentage of the parameter, %% !!! log scale?
  \item \T{prop}: a proportion, expressed in logit units,
  \item \T{coef}: a coefficient in the linear predictor of a regression model,
  \item \T{drop}: the effect of dropping a term from a regression model,
  \item \T{pred}: the effect of a term on the prediction accuracy.
  \end{itemize}
\item \T{show.inference}: selects the inference items to be presented by the 
  \T{print} methods.
  Currently, three styles are implemented:
  \begin{itemize}
  \item \T{relevance}: selects the columns determined by
    \T{getOption("show.simple.relevance")}, \linebreak
    \T{getOption("show.terms.relevance")}
    and \T{getOption("show.termeffects.relevance")}, for the three 
    print methods (see below), repectively; 
    these are the important columns for inference based on relevance;
  \item \T{classical, test}: selects \T{getOption("show.?.classical")}, 
    in the same manner, suitable for inference based on p values or
    significance, respectively.
  \end{itemize}
  The choice of any elements of the vector resulting from a call of
  \T{towsamples} or any columns of a \T{termtable} object is achieved by 
  typing, e.g., \T{options(show.ifc=c("classical","Sig0","Rls"))}.
\item \T{rlv.symbols} and \T{p.symbols}:
  symbols to be used for characterizing \T{Rls} or p-values, respectively,
\item \T{digits.reduced}: digits used for relevance and significance measures 
  and test statistics. These numbers are rounded to \T{digits.reduced} decimals,
  \T{p-values} to one more.
\item  \T{na.print}: symbol to print \T{NA} values.
\end{itemize}
The package's defaults can always be restored by typing
\T{options(relevance.options)}

<<getOption>>=
t.opt <- options(show.term.relevance=c("coef", "dropRls", "dropRls.symbol"))
rt
## restore the old options
options(list = t.opt)
@ 

\Tit{Function \T{print}.} 
These options are used when calling the \T{print} methods on the objects 
produced by the functions in Section \ref{sec:functions}.
These objects are either of class \T{inference} or \T{termeffects}.
The methods \T{print.inference} and \T{print.termeffects}
convert such objects into printable form by producing an object of
class \T{printInference}. They terminate by calling the method
\T{print.printInference}, which in turn produces the output---unless 
\T{print=FALSE} is set.
This two-step procedure allows for editing the output in the following
manner: 
<<printlist>>=
rr <- print(termeffects(r.blast), print=FALSE)
attr(rr, "head") <- sub("lm", "Linear Regression", attr(rr, "head"))
print(rr)
@ 


%% ============================================================================
\subsection*{Reference}

Stahel, Werner A. (2021). 
\textit{New relevance and significance measures to replace p-values} 
Submitted to PLoS ONE

\vspace{20mm}
{\small
\Tit{\noindent This is the end} 
of the story for the time being, \the\day.\the\month.\the\year. 

\noindent
Werner Stahel, \T{stahel at stat.math.ethz.ch}
}
\end{document}

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: t
%%% End: 
