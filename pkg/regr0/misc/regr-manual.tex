\documentclass{article}
\usepackage[ae,hyper]{Rd}
\usepackage{/u/stahel/R/Pkgs/regr0/misc/latex-regr}
\begin{document}
\Packagedescription

\HeaderA{asinperc}{arc sine Transformation}{asinperc}
\keyword{manip}{asinperc}
\begin{Description}\relax
Calculates the sqrt arc sine of x/100, rescaled to be in the unit
interval.\\
This transformation is useful for analyzing percentages or proportions
of any kind.
\end{Description}
\begin{Usage}
\begin{verbatim}
asinperc(x)
\end{verbatim}
\end{Usage}
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] vector of data values
\end{ldescription}
\end{Arguments}
\begin{Value}
vector of transformed values
\end{Value}
\begin{Note}\relax
This very simple function is provided in order to simplify formulas
\end{Note}
\begin{Author}\relax
Werner A. Stahel, ETH Zurich
\end{Author}
\begin{Examples}
\begin{ExampleCode}
asinperc(seq(0,100,10))
\end{ExampleCode}
\end{Examples}

\HeaderA{d.blast}{tremor caused by blasting for excavation of a tunnel, with
explanatory information}{d.blast}
\keyword{datasets}{d.blast}
\begin{Description}\relax
When excavating a tunnel, blasting may cause damage in houses 
in the neighborhood. It is important to keep the tremor caused by the
blasting under control. To this end, tremor is measured.
There were 4 devices to measure tremor. They were moved to different
locations while the excavation advanced.
\end{Description}
\begin{Usage}
\begin{verbatim}data(d.blast)\end{verbatim}
\end{Usage}
\begin{Format}\relax
A data frame with 388 observations on the following 7 variables.
\describe{
\item[\code{no}] number of blasting
\item[\code{datetime}] date and time of the blasting
\item[\code{device}] measurement device
\item[\code{charge}] charge (loading) in kg
\item[\code{distance}] between place of blasting and location
\item[\code{tremor}] measured in mm/s
\item[\code{location}] house in which tremor was measured
}
\end{Format}
\begin{Source}\relax
Basler \& Hofmann, Zurich
\end{Source}
\begin{Examples}
\begin{ExampleCode}
data(d.blast)
doc(d.blast)
coplot(log10(tremor)~distance|charge*location, data=d.blast)
\end{ExampleCode}
\end{Examples}

\HeaderA{d.fossiles}{Shapes of Shells and Environmental Variables}{d.fossiles}
\keyword{datasets}{d.fossiles}
\begin{Description}\relax
This dataset relates shapes of Gephyrocapsa shells with environmental
variables
\end{Description}
\begin{Usage}
\begin{verbatim}data(d.fossiles)\end{verbatim}
\end{Usage}
\begin{Format}\relax
The format is:
chr "d.fossiles"
\end{Format}
\begin{Details}\relax
NA
\end{Details}
\begin{Source}\relax
Joerg Bollmann, Jorijntje Henderiks and Bernhard Brabec,
Geological Institute, ETH Zurich,
\end{Source}
\begin{References}\relax
Joerg Bollmann, Jorijntje Henderiks and Bernhard Brabec,
Geological Institute, ETH Zurich,\\
Marine Micropaleontology 29, 319-350 (1997)
\end{References}
\begin{Examples}
\begin{ExampleCode}
data(d.fossiles)
showd(d.fossiles)
regr(cbind(sAngle,lLength,rWidth)~SST.Mean+Salinity+lChlorophyll+region+N,
                data=d.fossiles)
\end{ExampleCode}
\end{Examples}

\HeaderA{d.rehab}{~~ data name/kind ... ~~}{d.rehab}
\keyword{datasets}{d.rehab}
\begin{Description}\relax
~~ A concise (1-5 lines) description of the dataset. ~~
\end{Description}
\begin{Usage}
\begin{verbatim}data(d.rehab)\end{verbatim}
\end{Usage}
\begin{Format}\relax
The format is:
chr "d.rehab"
\end{Format}
\begin{Details}\relax
If necessary,
\end{Details}
\begin{Source}\relax
...
\end{Source}
\begin{Examples}
\begin{ExampleCode}
data(d.rehab)
\end{ExampleCode}
\end{Examples}

\HeaderA{d.surveyenvir}{Survey on Environment}{d.surveyenvir}
\keyword{datasets}{d.surveyenvir}
\begin{Description}\relax
A survey was conducted on attitudes towards environmental problems
\end{Description}
\begin{Usage}
\begin{verbatim}data(d.surveyenvir)\end{verbatim}
\end{Usage}
\begin{Format}\relax
A data frame with 2038 observations on the following 10 variables.
\describe{
\item[\code{age}] numeric. age in years
\item[\code{sex}] gender, either \code{m} for men or \code{f} for women
\item[\code{education}] level of education, with levels
\code{no.training}, \code{apprentiship}, \code{no.degree},
\code{college}, \code{uni}
\item[\code{location}] type of living environment, with levels
\code{Zentrum}, \code{Stadt.dicht}, \code{Stadt.locker}
\code{Rand.dicht}, \code{Rand.locker}, \code{Land}, \code{sonstig}
\item[\code{townsize}] size of town, with categories
\code{<2000}, \code{2000-4999}, \code{5000-19999}, \code{20000-49999}
\code{50000-99999}, \code{100000-499999}, \code{>500000} inhabitants
\item[\code{party}] political party, \code{CDU}, \code{SPD},
\code{FDP}, \code{NPD}, \code{DKP}, \code{Gruene},
\code{sonstige}, \code{keine}
\item[\code{disturbance}] level of disturbance, \code{nicht}
\code{etwas}, \code{ziemlich}, \code{sehr} 
\item[\code{gov}] Is the government active enough?
Levels \code{does.enough}, \code{not.enough}
\item[\code{responsability}] Who has the main responsibility?
Answers \code{individuals}, \code{government}, \code{both} 
\item[\code{weight}] weight of the observation according to sampling
design
}
\end{Format}
\begin{Source}\relax
"Umweltschutz im Privatbereich.",
Erhebung des EMNID, Zentralarchiv fuer empirische Sozialforschung
der Universitaet Koeln
\end{Source}
\begin{Examples}
\begin{ExampleCode}
data(d.surveyenvir)
t.r <- regr(disturbance~age+education+location, data=d.surveyenvir)
\end{ExampleCode}
\end{Examples}

\HeaderA{datatype}{Determine the Types of Variables}{datatype}
\keyword{attribute}{datatype}
\begin{Description}\relax
Determines the types of the variables (columns) of a data.frame
\end{Description}
\begin{Usage}
\begin{verbatim}
datatype(data)
\end{verbatim}
\end{Usage}
\begin{Arguments}
\begin{ldescription}
\item[\code{data}] a data.frame
\end{ldescription}
\end{Arguments}
\begin{Details}\relax
A type is determined for every variable (column) of the data.frame.
The types are:
\description{
\item[c] continuous variable
\item[b] binary variable. There is no distinction between factors
and logical variables or numerical variables having only 2 distint
values. 
\item[f] factor (not ordered)
\item[o] ordered factor
}
This information is used by \code{\LinkA{regr}{regr}} to determine the
adequate handling of the variables for modelling.
\end{Details}
\begin{Value}
the data.frame with two additional attributes: containing
\begin{ldescription}
\item[\code{vartype}] the variable types as described in Details
\item[\code{binlevels}] a list containing the levels of the binary variables
\end{ldescription}
\end{Value}
\begin{Author}\relax
Werner A. Stahel, ETH Zurich
\end{Author}
\begin{Examples}
\begin{ExampleCode}
data(d.blast)
dd <- datatype(d.blast[1:50,])
attr(dd,"vartype")
dr <- datatype(d.blast[as.numeric(d.blast$location)<=2,])
attr(dr,"vartype")
attr(dr,"binlevels")
\end{ExampleCode}
\end{Examples}

\HeaderA{doc}{Define and obtain the doc or tit attribute}{doc}
\aliasA{doc<\Rdash}{doc}{doc<.Rdash.}
\aliasA{tit}{doc}{tit}
\aliasA{tit<\Rdash}{doc}{tit<.Rdash.}
\keyword{attribute}{doc}
\begin{Description}\relax
The attributes \code{doc} and \code{tit} describe an object, typically
a data frame or a model. \code{tit} should be a short description (title),
\code{doc} should contain all documentation useful to identify
the origin and the changes made to the object.\\
The \code{doc} and \code{tit} functions set them and extract these
attributes.
\end{Description}
\begin{Usage}
\begin{verbatim}
doc(x)
tit(x) 
doc(x) <- text
tit(x) <- string
\end{verbatim}
\end{Usage}
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] object to which the \code{doc} attribute should be attached
or from which it is obtained
\item[\code{text}] character vector to be stored
\item[\code{string}] character string to be stored as title
\end{ldescription}
\end{Arguments}
\begin{Details}\relax
Plotting and printing functions may search for the \code{tit}
attribute or even for the \code{doc} attribute, depending on
\code{c.env\$docout}.

\code{doc(x) <- text} will append the existing \code{doc(x)} text to
the new one unless the first element of text equals \code{"\textasciicircum{}"},
whereas \code{tit(x) <- string} replaces \code{tit(x)}.
\end{Details}
\begin{Value}
\code{doc} and \code{tit} return the respective attributes of object
\code{x}
\end{Value}
\begin{Author}\relax
Werner A. Stahel, ETH Zurich
\end{Author}
\begin{Examples}
\begin{ExampleCode}
data(d.blast)
doc(d.blast)
doc(d.blast) <- "I will use this dataset in class soon."
doc(d.blast)
\end{ExampleCode}
\end{Examples}

\HeaderA{drop1.mlm}{Drop All Possible Single Terms from or Add Terms to a Multivariate Model}{drop1.mlm}
\aliasA{add1.mlm}{drop1.mlm}{add1.mlm}
\begin{Description}\relax
\code{drop1.mlm} / \code{add1.mlm} performs a test for the suitability
of dropping / adding each term in scope from / to a multivariate
regression or manova model
\end{Description}
\begin{Usage}
\begin{verbatim}
drop1(object, scope = NULL,
  test = c("Wilks", "Pillai", "Hotelling-Lawley", "Roy"), total = TRUE,
    add=FALSE, ...)
add1(object, scope = NULL,
  test = c("Wilks", "Pillai", "Hotelling-Lawley", "Roy"), ...)
\end{verbatim}
\end{Usage}
\begin{Arguments}
\begin{ldescription}
\item[\code{object}] a multivariate regression or manova object, possibly
with class \code{regr}
\item[\code{scope}] as in general \code{drop1 / add1} 
\item[\code{test}] multivariate test to be used
\item[\code{total}] should the test for null model also be performed?
\item[\code{add}] if TRUE, the function performs \code{add1} instead of
dropping terms
\item[\code{...}] not used
\end{ldescription}
\end{Arguments}
\begin{Value}
matrix containing statistics for each term
\end{Value}
\begin{Note}\relax
Note that \code{regr} performs such a (Wilks) test automatically.
Bug: extract.AIC is not yet available
\end{Note}
\begin{Author}\relax
modification of summary.manova by W. Stahel
\end{Author}
\begin{SeeAlso}\relax
\code{\LinkA{drop1.regr}{drop1.regr}}, \code{\LinkA{drop1.lm}{drop1.lm}}
\end{SeeAlso}
\begin{Examples}
\begin{ExampleCode}
data(d.fossiles)
r.lm <-
  lm(cbind(sAngle,lLength,rWidth)~SST.Mean+Salinity+lChlorophyll+region+N,
                data=d.fossiles)
drop1(r.lm)  ##  should be the same as summary(manova(...)) for its last row.
r.mregr <-
  regr(cbind(sAngle,lLength,rWidth)~SST.Mean+Salinity+lChlorophyll+region+N,
                data=d.fossiles)
r.mregr$drop1
drop1(r.mregr, test="Pillai")
\end{ExampleCode}
\end{Examples}

\HeaderA{drop1.regr}{Drop All Possible Single Terms from or Add Terms to a Model
Fitted by regr}{drop1.regr}
\aliasA{add1.regr}{drop1.regr}{add1.regr}
\aliasA{drop1.multinom}{drop1.regr}{drop1.multinom}
\keyword{regression}{drop1.regr}
\begin{Description}\relax
\code{drop1.regr} / \code{add1.regr} performs a test for the suitability
of dropping / adding each term in scope from / to a regression model
fitted by \code{\LinkA{regr}{regr}}
\end{Description}
\begin{Usage}
\begin{verbatim}
drop1(object, scope = NULL, scale = 0, test = NULL, k = 2,
            sorted = FALSE, add=FALSE, ...)
add1(object, scope = NULL, scale = 0, test = NULL, k = 2, sorted = FALSE, ...)
\end{verbatim}
\end{Usage}
\begin{Arguments}
\begin{ldescription}
\item[\code{object}] a fitted model object
\item[\code{scope}] a formula giving the terms to be considered for dropping
or adding.
Defaults to the terms in the \code{object}s formula for \code{drop1}
and to all first order interactions between these for \code{add1}
\item[\code{scale}] an estimate of the error variance if applicable. Will be
recalculated from the fit if ==0 or NULL
\item[\code{test}] see \code{\bsl{}lind\{droq1\}}
\item[\code{k}] the penalty constant in AIC / Cp
\item[\code{sorted}] if TRUE, the result is sorted according to the AIC or,
if absent, the p value
\item[\code{add}] converts \code{drop1.regr} into an add1 method
\item[\code{...}] further argiuments passed to the model specific methods
\end{ldescription}
\end{Arguments}
\begin{Value}
A data.frame of class '"anova"' summarizing the differences in fit
between the models obtained by dropping or adding the terms and the
original model given by \code{object}
\end{Value}
\begin{Author}\relax
Werner A. Stahel, ETH Zurich
\end{Author}
\begin{SeeAlso}\relax
\code{\LinkA{drop1}{drop1}}, \code{\LinkA{add1}{add1}}
\end{SeeAlso}
\begin{Examples}
\begin{ExampleCode}
  data(d.blast)
  t.r <- regr(log10(tremor)~location+log10(distance)+log10(charge), data=d.blast)
  drop1(t.r)
  add1(t.r)
\end{ExampleCode}
\end{Examples}

\HeaderA{dropdata}{Drop Observations from a Data.frame}{dropdata}
\keyword{manip}{dropdata}
\begin{Description}\relax
Allows for dropping observations (rows) determined by row names or
factor levels from a data.frame or matrix.
\end{Description}
\begin{Usage}
\begin{verbatim}
dropdata(data, rowid, incol = "row.names")
\end{verbatim}
\end{Usage}
\begin{Arguments}
\begin{ldescription}
\item[\code{data}] a data.frame of matrix
\item[\code{rowid}] vector of character strings identifying the rows to be
dropped
\item[\code{incol}] name or index of the column used to identify the
observations (rows)
\end{ldescription}
\end{Arguments}
\begin{Value}
The data.frame or matrix without the dropped observations.
Attributes are kept.
\end{Value}
\begin{Note}\relax
Ordinary subsetting by \code{[...,...]} drops attributes like
\code{\LinkA{doc}{doc}} or \code{\LinkA{tit}{tit}}. Furthermore, row or column
names cannot be used like indices, simply by a preceding minus sign to
drop the respective data.
\end{Note}
\begin{Author}\relax
Werner A. Stahel, ETH Zurich
\end{Author}
\begin{Examples}
\begin{ExampleCode}
dd <- rbind(a=1:3,b=4:6,c=7:9)
dropdata(dd,"b")
\end{ExampleCode}
\end{Examples}

\HeaderA{fitcomp}{Component Effects for a Model Fit}{fitcomp}
\keyword{regression}{fitcomp}
\begin{Description}\relax
Determines effects of varying each of the given variables while all
others are held constant. This function is mainly used to produce
plots of residuals versus explanatory variables, also showing
component effects.
\end{Description}
\begin{Usage}
\begin{verbatim}
fitcomp(object, data = NULL, vars = NULL, se = FALSE,
  xm = NULL, xfromdata = FALSE, nxcomp = 51)
\end{verbatim}
\end{Usage}
\begin{Arguments}
\begin{ldescription}
\item[\code{object}] a model fit, result of a fitting function
\item[\code{data}] data frame in which the variables are found
\item[\code{vars}] character vector of variable names which are used in
addition to all variables in the \code{formula} of \code{object} 
\item[\code{se}] if TRUE, standard errors will be returned
\item[\code{xm}] named vector of values of the fixed (central) point from
which the individual variables are varied in turn. \\
Defaults to the componentwise median of quantitative variables and
the modes of factors.
\item[\code{xfromdata}] if TRUE, the components effects will be evaluated for
the data values in \code{data}, otherwise, the range of each
variable is filled with \code{nxcomp} equidistant points.
This is useful for residual plots with component effects
\item[\code{nxcomp}] number of points used for each (quantitative) variable
if \code{xfromdata} is \code{FALSE}
\end{ldescription}
\end{Arguments}
\begin{Details}\relax
The component effect is defined as the curve of fitted values
obtained by varying the explanatory variable, keeping all the other
variables at their "central value" (the mean of continuous variables
and the mode of factors).
\end{Details}
\begin{Value}
A list consisting of
\begin{ldescription}
\item[\code{comp}] component effects
\item[\code{x}] the values of the x variables for which the effects have been
calculated
\item[\code{xm}] the values of the x variables that are held fixed while one
of the variables is varied
\item[\code{se}] standard errors of the component effects, if required by the
argument \code{se}
\end{ldescription}
\end{Value}
\begin{Author}\relax
Werner A. Stahel, ETH Zurich
\end{Author}
\begin{SeeAlso}\relax
\code{\LinkA{predict}{predict}}
\end{SeeAlso}
\begin{Examples}
\begin{ExampleCode}
data(d.blast)
t.r <- regr(log10(tremor)~location+log10(distance)+log10(charge), data=d.blast)
fitcomp(t.r,se=TRUE)
\end{ExampleCode}
\end{Examples}

\HeaderA{fitted.polr}{Fitted Values for polr objects}{fitted.polr}
\keyword{regression}{fitted.polr}
\begin{Description}\relax
Calculates Fitted Values for ordered response regression.
In addition to the types of the usual version, this function allows
for extracting the \code{link} type of predictions.
\end{Description}
\begin{Usage}
\begin{verbatim}
fitted(object, type = "link", na.action = object, ...)
\end{verbatim}
\end{Usage}
\begin{Arguments}
\begin{ldescription}
\item[\code{object}] an object that inherits from class \code{polr}
\item[\code{type}] type of fitted values (as with \code{predict}).
\description{
\item[\code{link}] asks for the linear predictor,
\item[\code{class}] returns the most likely (integer) Y values
\item[\code{probs}] returns probabilities for each value of Y
}


\item[\code{na.action}] object that possibly contains an \code{na.action}
component. If it is of the class \code{exclude}, the fitted values
will be expanded to fit the number of rows in the data.frame used
for fitting the regression.
\item[\code{...}] not used
\end{ldescription}
\end{Arguments}
\begin{Value}
Vector of fitted values
\end{Value}
\begin{Author}\relax
Werner A. Stahel, Seminar for Statistics, ETH Zurich
\end{Author}
\begin{Examples}
\begin{ExampleCode}
house.plr <- polr(Sat ~ Infl + Type + Cont, weights = Freq, data = housing)
house.fit <- fitted(house.plr, type="link") # only possible with regr version
\end{ExampleCode}
\end{Examples}

\HeaderA{lassoselect}{Model Selection by Lasso}{lassoselect}
\keyword{regression}{lassoselect}
\begin{Description}\relax
Calculate the Lasso estimates for the coefficients of a linear
regression model and select the model with smallest cross validated
mean square prediction error
\end{Description}
\begin{Usage}
\begin{verbatim}
lassoselect(object, data, s = NA, cv = is.na(s), cv.k=10,
  cv.s = seq(0,1,length=100), adaptive = TRUE,
  coefficients = object$coefficients, ...)
\end{verbatim}
\end{Usage}
\begin{Arguments}
\begin{ldescription}
\item[\code{object}] either a formula or a result of an earlier call to lassoselect
\item[\code{data}] data frame in which the formula is evaluated
\item[\code{s}] importance of L1 penalty given as in
\code{predict.lars (mode="fraction")}\\
if NA, \code{s} is determined by cross validation
\item[\code{cv}] calculate cross validated mean squared prediction error
(see  \code{\LinkA{cv.lars}{cv.lars}} )
\item[\code{cv.k}] k-fold cross-validation is used, where k=\code{cv.k}
\item[\code{cv.s}] fractions for which cross-validation ist done
\item[\code{adaptive}] if TRUE, the L1 penalty is \code{sum(abs(beta/coefficients))}
where  \code{coefficients}  is given as the next argument
\item[\code{coefficients}] named vector of initial coefficients used as
inverse weights in the L1 penalty. Only needed if adaptive is
TRUE.\\If \code{NULL}, \code{lassoselect} is called with
\code{adaptive=FALSE} to get these preliminary coefficients.

\item[\code{...}] arguments passed to \code{cv.lars} 
\end{ldescription}
\end{Arguments}
\begin{Value}
List consisting of the components
\begin{ldescription}
\item[\code{lars}] result of the call to \code{lars}, see \code{\LinkA{lars}{lars}}
\item[\code{data}] the data used
\item[\code{formula}] the formula used
\item[\code{s}] the fraction value for which the optimal model results
\item[\code{coefficients}] the coefficients of the optimal model
\item[\code{fitted}] the fitted values for the optimal model
\item[\code{adaptive}] indicates if adaptive lasso has been used
\item[\code{cv}] data.frame containing the results of cross validation\\
with columns \code{fraction, cv, cv.error} 
\end{ldescription}
\end{Value}
\begin{Author}\relax
Werner A. Stahel, ETH Zurich
\end{Author}
\begin{References}\relax
see \code{?lars} and ... for adaptive lasso
\end{References}
\begin{SeeAlso}\relax
\code{\LinkA{lars}{lars}}
\end{SeeAlso}
\begin{Examples}
\begin{ExampleCode}
## data(d.blast)
## t.r <- lassoselect(log10(tremor)~location+log10(distance)+log10(charge),
##                    data=d.blast)
## plot(t.r)
\end{ExampleCode}
\end{Examples}

\HeaderA{last}{Last Elements of a Vector}{last}
\keyword{manip}{last}
\begin{Description}\relax
Selects or drops the last element or the last \code{n} elements of a vector
\end{Description}
\begin{Usage}
\begin{verbatim}
last(data, n = 1)
\end{verbatim}
\end{Usage}
\begin{Arguments}
\begin{ldescription}
\item[\code{data}] vector from which to select or drop
\item[\code{n}] if >0, \code{last} selects the last \code{n} elements form
the result.\\ 
if <0, the last \code{abs(n)} elements are dropped, and the first
\code{length(data)-abs(n)} elements from the result
\end{ldescription}
\end{Arguments}
\begin{Value}
The selected elements of the vector
\end{Value}
\begin{Note}\relax
This is a very simple function. It is defined mainly for selecting
from the results of other functions without storing them.
\end{Note}
\begin{Author}\relax
Werner Stahel
\end{Author}
\begin{Examples}
\begin{ExampleCode}
  x <- runif(rpois(1,10))
  last(sort(x), 3)
  last(sort(x), -5)
\end{ExampleCode}
\end{Examples}

\HeaderA{legendr}{Add a Legend to a Plot}{legendr}
\keyword{aplot}{legendr}
\begin{Description}\relax
Adds a legend to a plot as does \code{\LinkA{legend}{legend}}. This function
just expresses the position relative to the range of the coordinates
\end{Description}
\begin{Usage}
\begin{verbatim}
legendr(x = 0.05, y = 0.95, ...)
\end{verbatim}
\end{Usage}
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] position in horizontal direction, between 0 for left margin
and 1 for right margin
\item[\code{y}] position in vertical direction, between 0 for bottom margin
and 1 for top margin
\item[\code{...}] arguments passed to \code{\LinkA{legend}{legend}}
\end{ldescription}
\end{Arguments}
\begin{Value}
See \code{\LinkA{legend}{legend}}
\end{Value}
\begin{Author}\relax
Werner A. Stahel, ETH Zurich
\end{Author}
\begin{SeeAlso}\relax
\code{\LinkA{legend}{legend}}
\end{SeeAlso}
\begin{Examples}
\begin{ExampleCode}
     ts.plot(ldeaths, mdeaths, fdeaths,xlab="year", ylab="deaths", lty=c(1:3))
     legendr(0.7,0.95, c("total","female","male"), lty=1:3)
\end{ExampleCode}
\end{Examples}

\HeaderA{logst}{Started Logarithmic Transformation}{logst}
\keyword{manip}{logst}
\begin{Description}\relax
Transforms the data by a log10 transformation, modifying small and zero
observations such that the transformation yields finite values.
\end{Description}
\begin{Usage}
\begin{verbatim}
logmin(data, mult = 1)
\end{verbatim}
\end{Usage}
\begin{Arguments}
\begin{ldescription}
\item[\code{data}] a vector of data
\item[\code{mult}] a tuning constant affecting the transformation of small
values, see Details
\end{ldescription}
\end{Arguments}
\begin{Details}\relax
Small values are determined by the quartiles  \eqn{q_1}{q1} and
\eqn{q_3}{q3} of the
non-zero data as those smaller than
\eqn{q_1 / (q_3/q_1)^{mult}}{q1 / (q3/q1)^{mult}}.
The rationale is that for lognormal data, this constant identifies
2 percent of the data as small.
Beyond this limit, the transformation continues linear with the
derivative of the log curve at this point. See code for the formula.

The function chooses log10 rather than natural logs because they can
be backtransformed relatively easily in the mind.
\end{Details}
\begin{Value}
the transformed data
\end{Value}
\begin{Note}\relax
The names of the function alludes to Tudey's idea of "started logs".
\end{Note}
\begin{Author}\relax
Werner A. Stahel, ETH Zurich
\end{Author}
\begin{Examples}
\begin{ExampleCode}
dd <- c(seq(0,1,0.1),5*10^rnorm(100,0,0.2))
dd <- sort(dd)
r.dl <- logst(dd)
plot(dd, r.dl, type="l")
abline(v=attr(r.dl,"threshold"),lty=2)
\end{ExampleCode}
\end{Examples}

\HeaderA{mframe}{Multiple Frames for Plotting}{mframe}
\keyword{utilities}{mframe}
\begin{Description}\relax
This is a short-cut to set some graphical parameters
\end{Description}
\begin{Usage}
\begin{verbatim}
mframe(mfrow = NULL, mfcol = NULL, mft = NULL, row = TRUE,
  oma = c(0, 0, 2, 1), mar = options("mar")[[1]], mgp =
  options("mgp")[[1]], ...)
\end{verbatim}
\end{Usage}
\begin{Arguments}
\begin{ldescription}
\item[\code{mfrow, mfcol}] number of rows and columns of panels. The default
is 1 for both, which will reset the subdivision of the plotting page.
\item[\code{mft}] total number of panels, to be split into \code{mfrow}
and \code{mfcol} by the function. The result depends on the current
aspect ratio (ratio of height to width) of the plotting area.
\item[\code{row}] if TRUE, the panels will be used by rows, otherwise, by columns
\item[\code{oma, mar, mgp, ...}] further graphical parameters passed to
\code{par(...)}
\end{ldescription}
\end{Arguments}
\begin{Details}\relax
The function calls \code{par}. Its purpose is to simplify a call like
\code{par(mfrow=c(3,4))} to \code{mframe(3,4)} and to set some
defaults differently from \code{par}
\end{Details}
\begin{Value}
list containing old values of parameters, as for \code{par}
\end{Value}
\begin{Author}\relax
Werner A. Stahel, Zurich
\end{Author}
\begin{SeeAlso}\relax
\code{\LinkA{par}{par}}
\end{SeeAlso}
\begin{Examples}
\begin{ExampleCode}
mframe(2,3)  
mframe(mft=15)  ## will split the plotting area into >= 15 panels, 
mframe()  ## reset to 1 panel
\end{ExampleCode}
\end{Examples}

\HeaderA{nainf.exclude}{Drop Rows Containing NA or Inf}{nainf.exclude}
\aliasA{nainf.omit}{nainf.exclude}{nainf.omit}
\keyword{NA}{nainf.exclude}
\keyword{manip}{nainf.exclude}
\begin{Description}\relax
Drops the rows of a data frame that contain an NA, an NaN, or an Inf value
\end{Description}
\begin{Usage}
\begin{verbatim}
nainf.exclude(object, ...)
\end{verbatim}
\end{Usage}
\begin{Arguments}
\begin{ldescription}
\item[\code{object}] an R object, typically a data frame
\item[\code{...}] further arguments special methods could require.
\end{ldescription}
\end{Arguments}
\begin{Details}\relax
This is a simple modification of \code{\LinkA{na.omit}{na.omit}} and
\code{\LinkA{na.exclude}{na.exclude}}
\end{Details}
\begin{Value}
The value is of the same type as the argument \code{object},
with possibly less elements.
\end{Value}
\begin{Author}\relax
Werner A. Stahel, ETH Zurich
\end{Author}
\begin{SeeAlso}\relax
\code{\LinkA{na.omit}{na.omit}}
\end{SeeAlso}
\begin{Examples}
\begin{ExampleCode}
t.d <- data.frame(V1=c(1,2,NA,4), V2=c(11,12,13,Inf))
nainf.exclude(t.d)
\end{ExampleCode}
\end{Examples}

\HeaderA{plTA.polr}{Plot Residuals against Fitted Values for polr objects}{plTA.polr}
\keyword{hplot}{plTA.polr}
\keyword{regression}{plTA.polr}
\begin{Description}\relax
Displays the "Tukey-Anscombe" plot for ordered regression models.
\end{Description}
\begin{Usage}
\begin{verbatim}
plTA.polr(object, colbars = grey(0.7), colref = grey(0.7), ploty = FALSE)
\end{verbatim}
\end{Usage}
\begin{Arguments}
\begin{ldescription}
\item[\code{object}] result of a call to \code{polr}
\item[\code{colbars}] color to be used for plotting the bars representing
the residuals
\item[\code{colref}] color for reference line
\item[\code{ploty}] if TRUE, the latent response will be plotted instead of
the residuals
\end{ldescription}
\end{Arguments}
\begin{Details}\relax
The plot intends to show the residuals for the latent variable Z that
determines the response values Y. Since the precise residuals of the
latent variable cannot be known, the plot shows their conditional
distribution, given the observed response values. This conditional
distribution is characerized by its median (by -) and the two other
quartiles (by vertical bars).
\end{Details}
\begin{Value}
none.
\end{Value}
\begin{Author}\relax
Werner A. Stahel, ETH Zurich
\end{Author}
\begin{References}\relax
See \code{http://stat.ethz.ch/\textasciitilde{}stahel/regression}
\end{References}
\begin{SeeAlso}\relax
\code{\LinkA{plot.regr}{plot.regr}}, \code{\LinkA{residuals.polr}{residuals.polr}}
\end{SeeAlso}
\begin{Examples}
\begin{ExampleCode}
house.plr <- polr(Sat ~ Infl + Type + Cont, weights = Freq, data = housing)
plTA.polr(house.plr)
\end{ExampleCode}
\end{Examples}

\HeaderA{plcoord}{Determines Values for Plotting with Limited "Inner" Plot Range}{plcoord}
\keyword{manip}{plcoord}
\keyword{aplot}{plcoord}
\begin{Description}\relax
For plots with an "inner plot range" (see Details) this function
converts the data values to the coordinates in the plot
\end{Description}
\begin{Usage}
\begin{verbatim}
plcoord(x, range = NULL, limfac = 3, limext = 0.1)
\end{verbatim}
\end{Usage}
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] data to be represented 
\item[\code{range}] vector of 2 elements giving the inner plot range. Data
beyond the given interval will be non-linearly transformed to fit
within the (outer) plot margins. Defaults to
\code{\LinkA{robrange}{robrange}(x, fac=fac)}.

\item[\code{limfac}] factor used to determine the default of \code{range} 
\item[\code{limext}] factor for extending the \code{range} to determine the
outer plot range 
\end{ldescription}
\end{Arguments}
\begin{Details}\relax
When plotting data that contain outliers, the non-outlying data is
represented poorly. Rather than simply clipping outliers, one can
split the plotting area into an inner region, where the (non-outlying)
data is plotted as usual, and a plot area margin, in which outliers
are represented on a highly non-linear scale that allows to display
them all.

This function converts the data to the coordinates used in the
graphical display, and also returns the inner range for plotting.
\end{Details}
\begin{Value}
vector of coordinates used for plotting, that is, unchanged \code{x}
values for   those within the \code{range} and transformed values
for those outside.

Attributes:
\begin{ldescription}
\item[\code{attr(,"range")}] the "inner" plot range, either the argument
\code{range} or the values determined by default.
\item[\code{attr(,"nmod")}] the number of modified observations
\end{ldescription}
\end{Value}
\begin{Author}\relax
Werner Stahel
\end{Author}
\begin{SeeAlso}\relax
\code{\LinkA{robrange}{robrange}}
\end{SeeAlso}
\begin{Examples}
\begin{ExampleCode}
  x <- c(rnorm(20),rnorm(3,5,20))
  xmod <- plcoord(x)
  plot(x,xmod)
  plot(xmod)
  abline(h=attr(xmod,"range"),lty=3, lwd=2)
\end{ExampleCode}
\end{Examples}

\HeaderA{plmatrix}{Scatterplot Matrix}{plmatrix}
\keyword{hplot}{plmatrix}
\begin{Description}\relax
Plots a scatterplot matrix, for which the variables shown horizontally
do not necessarily coincide with those shown vertically. If desired,
the matrix is divided into several blocks such that it fills more than
1 plot page.
\end{Description}
\begin{Usage}
\begin{verbatim}
plmatrix(data1, data2 = NULL, data = NULL, panel = l.panel,
  nrows = 0, ncols = 0, save = TRUE,
  robrange. = FALSE, range. = NULL, pch = NULL, clr = 1, 
  reference = 0, ltyref = 3, log = "", xaxs = "r", yaxs = "r", vnames = NULL,
  main = "", cex = NA, cexlab = 1.3, cextext = 1, cex.title = 1,
  bty = "o", oma = NULL, ...)
\end{verbatim}
\end{Usage}
\begin{Arguments}
\begin{ldescription}
\item[\code{data1}] data for rows (y axis), or formula defining row variables
\item[\code{data2}] data or formula for columns (x axis). Defaults to \code{data1}
\item[\code{data}] data.frame containing the variables in case \code{data1}
or \code{data2} is a formula
\item[\code{panel}] a function that generates the marks of the individual
panels, see Details.
Defaults essentially to \code{\LinkA{points}{points}} or \code{\LinkA{text}{text}}
depending on the argument \code{pch}
\item[\code{nrows}] number of rows of panels on a page
\item[\code{ncols}] number of columns of panels on a page
\item[\code{save}] if data2 is not provided and \code{save==TRUE},
the first row and the last column are suppressed.
\item[\code{robrange.}] if TRUE, robust plot ranges will be used
\item[\code{range.}] plot ranges, given as a matrix with 2 rows (min, max)
and \code{colnames} identifying the variables.
\item[\code{pch}] plotting character. A vector of integers, characters or
strings can also be given for the default panel function
\item[\code{clr}] color(s) to be used for plotting the observations
\item[\code{reference}] coordinates for reference lines to be shown in the
panels. A named vector can be used to define a value for each or
any variable.
\item[\code{ltyref}] line type for reference lines
\item[\code{log}] specifies logarithmic scale of axes. \code{"x"} asks for
log scale on horizontal axis, \code{"y"}, on vertical axis,
\code{"xy"}, on both axes.
\item[\code{xaxs, yaxs}] styles for x and y axis, see \code{\LinkA{par}{par}}
\item[\code{vnames}] labels for the variables
\item[\code{main}] main title for the plot (to be repeated on each plot page)
\item[\code{cex}] character expansion for showing the observations
\item[\code{cexlab, cextext}] character expansion for variable labels
in the margin and in the "diagonal", respectively,
relative to \code{cex}
\item[\code{cex.title}] character expansion for the main title
\item[\code{bty}] box type for each panel, see \code{\LinkA{par}{par}}
\item[\code{oma}] width of outer margins, ee \code{\LinkA{par}{par}}
\item[\code{...}] further arguments passed to the \code{panel} function
\end{ldescription}
\end{Arguments}
\begin{Details}\relax
If \code{data1} or \code{data2} is a data.frame, it is converted to a
numerical matrix.

The \code{panel} function can be user written. It needs \eqn{>=6}{} arguments,
which are given:
\Itemize{
\item the values of the horizontal variable,
\item the values of the vertical variable,
\item the index of the variable shown horizontally, among the
\code{data2} variables,
\item the index of the variable shown vertically, among the
\code{data1} variables,
\item argument \code{pch}, and
\item argument \code{clr}
}

Since large scatterplot matrices lead to tiny panels, \code{plmatrix}
splits the matrix into blocks of at most \code{nrows} rows and
\code{ncols} columns. If these numbers are missing, they default to
\code{nrows=5} and \code{ncols=6} for landscape pages, and to
\code{nrows=8} and \code{ncols=5} for portrait pages.
\end{Details}
\begin{Value}
none
\end{Value}
\begin{Author}\relax
Werner A. Stahel, ETH Zurich
\end{Author}
\begin{SeeAlso}\relax
\code{\LinkA{pairs}{pairs}}
\end{SeeAlso}
\begin{Examples}
\begin{ExampleCode}
plmatrix(iris[,1:4], main="Iris", pch=as.numeric(iris[,"Species"]))
\end{ExampleCode}
\end{Examples}

\HeaderA{plfitpairs}{Plot Fitted Values for Multinomial Regression}{plfitpairs}
\keyword{hplot}{plfitpairs}
\begin{Description}\relax
Displays a scatterplot matrix of fitted values obtained from a
multinomial regression. !!! to be repaired
\end{Description}
\begin{Usage}
\begin{verbatim}
plfitpairs(object, ssize = 0.02, main = NULL)
\end{verbatim}
\end{Usage}
\begin{Arguments}
\begin{ldescription}
\item[\code{object}] result of fitting \code{multinom}, possibly
through \code{\LinkA{regr}{regr}}
\item[\code{ssize}] symbol size
\item[\code{main}] plot title
\end{ldescription}
\end{Arguments}
\begin{Value}
none.
\end{Value}
\begin{Author}\relax
Werner A. Stahel, ETH Zurich
\end{Author}

\HeaderA{plot.lassoselect}{Plot a Lassoselect Object}{plot.lassoselect}
\keyword{hplot}{plot.lassoselect}
\keyword{regression}{plot.lassoselect}
\begin{Description}\relax
Plots the coefficients as a function of the tuning parameter "s" of
the L1 penalty term in the lasso model selection method and the cross
validated mean square prediction error.
\end{Description}
\begin{Usage}
\begin{verbatim}
  plot(x, plot.s = TRUE, plot.cv = TRUE, plot.cvse = TRUE, main = "", ...)
\end{verbatim}
\end{Usage}
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] the result of \code{\LinkA{lassoselect}{lassoselect}}
\item[\code{plot.s}] if TRUE, the coefficients will be plotted
\item[\code{plot.cv}] if TRUE, the cross validated mean square prediction
error will be plotted
\item[\code{plot.cvse}] if TRUE, error bars for these values will be plotted
\item[\code{main}] main title of plot
\item[\code{...}] further arguments, passed to \code{plot.lars}
\end{ldescription}
\end{Arguments}
\begin{Value}
none.
\end{Value}
\begin{Note}\relax
\code{plot.lars} has been slightly modified
\end{Note}
\begin{Author}\relax
Werner A. Stahel, ETH Zurich
\end{Author}
\begin{SeeAlso}\relax
\code{\LinkA{plot.lars}{plot.lars}}
\end{SeeAlso}
\begin{Examples}
\begin{ExampleCode}
## data(d.blast)
## t.r <- lassoselect(log10(tremor)~location+log10(distance)+log10(charge),
##                    data=d.blast)
## plot(t.r)
\end{ExampleCode}
\end{Examples}

\HeaderA{plot.regr}{Diagnostic Plots for Regr Objects}{plot.regr}
\keyword{hplot}{plot.regr}
\keyword{regression}{plot.regr}
\begin{Description}\relax
Diagnostic plots for fitted regression models:
Residuals versus fit (Tukey-Anscombe plot) and/or target variable
versus fit;
Absolute residuals versus fit to assess equality of error variances;
Normal Q-Q plot (for ordinary regression models);
Residuals versus leverages to identify influential observations;
Residuals versus sequence;
and Residuals versus explanatory variables.
These plots are adjusted to the type of regression model.
\end{Description}
\begin{Usage}
\begin{verbatim}
plot(x, data = NULL, markprop = NULL, lab = NULL, cex.lab = 0.7,
  mf = NULL, mfcol=FALSE, mar=c(3,3,2,1), mgp=c(2,0.7,0),
  oma = 2*(prod(mf)>1), cex=par("cex"), ask = NULL, 
  multnrows = 0, multncols = 0,
  lty = c(1, 2, 5, 3, 4, 6), lwd = c(1,1,2,1,1.5,1),
  colors = c.env$colors.ra, pch = NULL,
  main = NULL, cex.title = NULL,
  wsymbols = NULL, symbol.size = NULL,
  smooth = TRUE, smooth.par = NA, smooth.iter = NA, 
  smooth.sim = 19, nxsmooth = 51,
  plotselect = NULL, 
  weights = NULL, hat.cooklim = 1:2, res.lim = TRUE, y.lim = TRUE,
  glm.restype = "deviance", sequence = NA,
  xplot = TRUE, x.se = FALSE, x.smooth = smooth, addcomp=FALSE, ...)
\end{verbatim}
\end{Usage}
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] regr 
object (result of a call to \code{regr}). Thiw iw the only argument
that is needed. All others have useful defaults.
\item[\code{data}] data set where explanatory variables are found
\item[\code{markprop}] proportion of extreme residuals to be labeled
\item[\code{lab}] labels of observations used to identify them
\item[\code{cex.lab}] character size for lab
\item[\code{mf}] vector of 2 elements, indicating the number of rows and
columns of panels on each plot page.
Defaults to \code{c(2,2)}, except for multivariate models, where
it adjusts to the number of target variables
\item[\code{mfcol}] if TRUE, the panel will be filled columnwise
\item[\code{mar, mgp, oma, cex, ask}] see \code{?par}
\item[\code{multnrows, multncols}] number of rows and columns of panels on
one page, for residuals of multivariate regression only
\item[\code{lty, lwd, colors}] three vectors of length 6 each, defining the
line types, line widths, and colors to be used for ...
\describe{
\item[[1] ] observations;
\item[[2] ] reference lines;
\item[[3] ] smooth;
\item[[4] ] simulated smooths;
\item[[5] ] component effects in plresx;
\item[[6] ] for confidence bands of component effects.
\item[[7] ] (random) observations in the case of
\code{glm.restype="cond.quant"};
\item[[8] ] bars showing conditional quantiles for
\code{glm.restype="cond.quant"};
}

\item[\code{pch}] plotting character to use for unlabeled points
\item[\code{main}] main title to be used on each page,
defaults to the formula of object
\item[\code{cex.title}] character size for title
\item[\code{wsymbols}] if TRUE, points are displayed by a bubble whose size
indicates the weight as given in \code{object\$weights}.
If it is a vector of appropriate size, it will be used to determine
the sizes of such bubbles.
\item[\code{symbol.size}] determines the size of weight symbols
\item[\code{smooth}] if TRUE, smooths are added to the plots where
appropriate. If it is a function, it is assumed to define the smooths.

\item[\code{smooth.par, smooth.iter}] arguments to the smooth function
\item[\code{smooth.lwd}] line width for plotting the smooth lines
\item[\code{smooth.sim}] number of simulated smooths added to each plot
\item[\code{nxsmooth}] number of values on the horizontal axes where smooths
are evaluated
\item[\code{plotselect}] which plots should be shown? See Details
\item[\code{weights}] if TRUE, residuals will be plotted versus
\code{object\$weights}. Alternatively, a vector of weights can be specified
\item[\code{hat.cooklim}] levels of Cook distance for which contours are
plotted in the leverage plot
\item[\code{res.lim}] limits for plotting residuals directly. Beyond these
limits, points are shown in the margins with squeezes scale
\item[\code{y.lim}] limits for plotting y values
\item[\code{glm.restype}] type of residuals to be used for glm model.
In addition to those allowed in \code{residuals()} for
\code{glm} objects, type \code{cond.quant} is possible for
(ungrouped) binary regression. See \code{?\LinkA{residuals.polr}{residuals.polr}} for
an explanation.
\item[\code{sequence}] logical: should residuals  be plotted versus sequence?
\item[\code{xplot}] if TRUE, residuals will be plotted versus all (raw)
explanatory variables in the model (by calling \code{plresx})
\item[\code{x.se}] logical: Should confidence bands be drawn in plot of residuals
versus explanatory variables?
\item[\code{x.smooth}] like \code{smooth}, for the latter plots
\item[\code{addcomp}] logical: should component effects be added to
residuals for residuals versus input variables plots? 
\item[\code{...}] further arguments to be passed to \code{plot}
\end{ldescription}
\end{Arguments}
\begin{Details}\relax
Argument \code{plotselect} is used to determine which plots will be
shown. It should be a named vector of numbers indicating
\describe{
\item[0] do not show
\item[1] show without smooth
\item[2] show with smooth
}
The default is
c( yfit=0, ta=3, tascale = NA, weights = NA, qq = NA, hat = 2,
resmatrix = 1, qqmult = 3).
Modify this vector to change the selection and the sequence in
which the plots appear.

The names of \code{plotselect} refer to:
\describe{
\item[yfit] response versus fitted values
\item[ta] residuals versus fitted values (Tukey-Anscombe plot)
\item[tascale] residuals versus fitted values, defaults to TRUE for
ordinary regression, FALSE for glm and others
\item[weights] residuals versus weights
\item[qq] normal Q-Q plot, defaults to TRUE for
ordinary regression, FALSE for glm and others
\item[hat] residuals versus leverage (hat diabgonal)
\item[resmatrix] scatterplot matrix of residuals for
multivariate regression
\item[qqmult] qq plot for Mahlanobis lengths versus sqrt of chisquare
quantiles.
}

In the Tukey-Anscombe plot, reference line indicates a "contour"
line with constant values of the response variable,
\eqn{Y=\widehat y+r=}{} constant. It has slope \code{-1}.
It is useful to judge whether any curvature shown by the smooth
might disappear after a nonlinear, monotone transformation of the
response.
\end{Details}
\begin{Value}
none
\end{Value}
\begin{Note}\relax
This is a function under development. Future versions may behave
differently and may not be compatible with this version.
\end{Note}
\begin{Author}\relax
Werner A. Stahel, ETH Zurich
\end{Author}
\begin{SeeAlso}\relax
plot.lm
\end{SeeAlso}
\begin{Examples}
\begin{ExampleCode}
  r.savings <- regr(sr ~ pop15 + pop75 + dpi + ddpi, data = LifeCycleSavings)
  plot(r.savings)

  data(d.blast)
  r.blast <-
       regr(log10(tremor)~location+log10(distance)+log10(charge),
            data=d.blast)
  plot(r.blast, seq=FALSE, xplot=~.+no) 

  data(d.fossiles)
  r.foss <-
    regr(cbind(sAngle,lLength,rWidth)~SST.Mean+Salinity+lChlorophyll+region+N,
    data=d.fossiles)
  plot(r.foss, plotselect=c(ta=3, resmatrix=1, qqmult=1),xplot=FALSE)
\end{ExampleCode}
\end{Examples}

\HeaderA{plres2x}{Plot Residuals vs. Two Explanatory Variables}{plres2x}
\keyword{hplot}{plres2x}
\keyword{regression}{plres2x}
\begin{Description}\relax
Plot 2 variables, showing a third one with line symbols. Most suitable
for showing residuals of a model as this third variable.
\end{Description}
\begin{Usage}
\begin{verbatim}
plres2x(formula = NULL, reg = NULL, data = reg, restricted = NULL,
size = 0, slwd = 1, scol = 2, xlab = NULL, ylab = NULL,
xlim = NULL, ylim = NULL, main = NULL, cex.title = NULL, ...)
\end{verbatim}
\end{Usage}
\begin{Arguments}
\begin{ldescription}
\item[\code{formula}] a formula of the form \code{z\textasciitilde{}x+y}, where
\code{x, y} are the 2 variables shown by the coordinates of points,
and z is shown by line symbols: their orientation corresponds
to the sign of \code{z}, and their length, to the absolute value.

\item[\code{reg}] the result of the model fit
\item[\code{data}] the data.frame where the variables are found
\item[\code{restricted}] absolute value which truncates the size. Truncation
is shown by stars at the end of the line symbols.

\item[\code{size}] the symbols are scaled so that \code{size} is the length of
the largest symbol, as a percentage of the length
of the horizontal axis. Defaults to \code{5/log10(n)}, where
\code{n} is the number of observations
\item[\code{slwd}] line width of the line symbols
\item[\code{scol}] color of the symbols
\item[\code{xlab, ylab}] labels for horizontal and vertical axes.
Default to the variable names
\item[\code{xlim, ylim}] plot ranges for horizontal and vertical axes.
They are expanded to accomodate the symbols
\item[\code{main}] main title of plot.
Defaults to \code{formula}
\item[\code{cex.title}] character expansion for the main title
\item[\code{...}] further arguments, passed to \code{plot}
\end{ldescription}
\end{Arguments}
\begin{Value}
none.
\end{Value}
\begin{Author}\relax
Werner A. Stahel and Andreas Ruckstuhl
\end{Author}
\begin{Examples}
\begin{ExampleCode}
  data(d.blast)
  t.r <- regr(log10(tremor)~location+log10(distance)+log10(charge),
            data=d.blast)
  plres2x(~distance+charge, t.r)
\end{ExampleCode}
\end{Examples}

\HeaderA{plresx}{Plot Residuals Against Explanatory Variables}{plresx}
\keyword{hplot}{plresx}
\keyword{regression}{plresx}
\begin{Description}\relax
Diagnostic plots for fitted regression models:
Residuals are plotted against explanatory variables,
including smooth for actual residuals and simulated ones,
as well as a reference reference line for constant values of the
response variable.
\end{Description}
\begin{Usage}
\begin{verbatim}
plresx(x, data = NULL, partial.resid = TRUE,
  glm.restype = "deviance", weights = NULL, lab = NULL, cex.lab = 1,
  vars = NULL, sequence = FALSE, se = FALSE,
  addcomp = FALSE, rug = FALSE, jitter = NULL,
  smooth = TRUE, smooth.par = NA, smooth.iter = NA, 
  smooth.sim = 19, nxsmooth = 51,
  lty = c(1,2,5,3,6,4,1,1), lwd = c(1,1,2,1,1.5,1,1,1),
  colors = c.env$colors.ra[[1]],
  xlabs = NULL, ylabs = NULL, main = NULL, cex.title = NULL,
  ylim = TRUE, ylimfac = 3, ylimext = 0.1,
  cex = par("cex"), wsymbols = NULL, symbol.size = NULL,
  ask = NULL, multnrows = 0, multncols = 0, ...)
\end{verbatim}
\end{Usage}
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] fitted regression object, result of calling \code{link\{regr\}}
\item[\code{data}] data set. defaults to the data set used when calling \code{regr}
\item[\code{partial.resid}] if TRUE (default),
residuals for observations will be displayed
\item[\code{glm.restype}] type of residuals to be plotted in case of a glm
model. In addition to those allowed in \code{residuals()} for
\code{glm} objects, type \code{cond.quant} is possible for
(ungrouped) binary regression. See \code{?\LinkA{residuals.polr}{residuals.polr}} for
an explanation.
\item[\code{weights}] weights to be used for smoothing as well as
plotting of observations without label
\item[\code{lab}] character string labels to be used for displaying observed
residuals
\item[\code{cex.lab}] character expansion for labels
\item[\code{vars}] variables against which the residuals shall be plotted.
Defaults to the variables contained in the formula of \code{object}.
\code{vars} can be a formula (of which all variables on the right
hand side will be used) or a character vector of variable names.
All variables must be contained in \code{data}
\item[\code{sequence}] if TRUE, the residuals are also plotted against their
sequence number
\item[\code{se}] if TRUE, standard errors of the fit are plotted
\item[\code{addcomp}] if TRUE, the component effect is added to the residuals
as is common for a "partial residual plot"
\item[\code{rug}] if TRUE, the "rug" is displayed. It consists of tick marks
for the observed values.
\item[\code{jitter}] amount of jitter to be added for displaying factors
\item[\code{smooth}] if TRUE, a smooth line will be fitted to each plot.
By default, \code{\LinkA{loess}{loess}} is used. Alternatively, another smoothing
function can be given as argument \code{smooth}
\item[\code{smooth.par}] parameter driving the smooth: argument \code{span}
if \code{loess} is used, which defaults to
\code{3*nobs\textasciicircum{}log10(1/2)*(1+glm)}, where \code{glm==1} for glm models
\item[\code{smooth.iter}] iterations used in the smoothing algorithm
\item[\code{smooth.sim}] number of simulated smooth lines to be drawn
\item[\code{nxsmooth}] number of x values for which the smooth is calculated
\item[\code{lty, lwd, colors}] vector of line types and colors to be used for \\
\describe{
\item[[1] ] observations (only \code{colors[1]} matters);
\item[[2] ] horizontal reference line;
\item[[3] ] smooth;
\item[[4] ] simulated smooths;
\item[[5] ] reference lines related to component effect;
\item[[6] ] for confidence bands of component effects;
\item[[7] ] (rnadom) observations in the case of
\code{glm.restype="cond.quant"};
\item[[8] ] bars showing conditional quantiles for
\code{glm.restype="cond.quant"};
}

\item[\code{xlabs}] labels of x variables to be used instead of those
given by \code{vars}
\item[\code{ylabs}] label for residuals
\item[\code{main}] main title
\item[\code{cex.title}] character expansion for main title
\item[\code{ylim}] if TRUE, the range of the y axis will be restricted by
calling \code{\LinkA{robrange}{robrange}}
\item[\code{ylimfac}] argument passed to \code{robrange}
\item[\code{ylimext}] argument passed to \code{robrange}
\item[\code{lwd.term}] line width for drawing component effects
\item[\code{cex}] character expansion
\item[\code{wsymbols}] if TRUE, weights are used as symbol size
\item[\code{symbol.size}] maximal symbol size, relative to \code{0.02*par("pin")[1]}
\item[\code{ask}] as in \code{\LinkA{par}{par}}
\item[\code{multnrows, multncols}] number of rows and columns for multiple
frames in case of multivatiate residuals
\item[\code{...}] further arguments passed to \code{plot}
\end{ldescription}
\end{Arguments}
\begin{Details}\relax
The plots have several unusual features:
\Itemize{
\item
Showing outliers in the plot margins and marking them with their
labels (if \code{markprop>0}).
\item
A reference line is shown. It follows a "contour" of an approximately
constant value of the response variable -- more precisely,
it shows the "component effect" with opposite sign.
It helps decide if a curvature shown by the smooth can be removed
by transforming the explanatory variable forming the horizontal
axis. The component effect is defined as the curve of fitted values
obtained by varying the explanatory variable, keeping all the other
variables at their "central value" (the mean of continuous variables
and the mode of factors).
}
\end{Details}
\begin{Value}
The names of the variables against which the residuals are plotted are
returned invisibly
\end{Value}
\begin{Note}\relax
This function is still under construction
\end{Note}
\begin{Author}\relax
Werner A. Stahel, ETH Zurich
\end{Author}
\begin{References}\relax
There will be a website
\end{References}
\begin{SeeAlso}\relax
\code{\LinkA{plot.regr}{plot.regr}}, \code{\LinkA{termplot}{termplot}}
\end{SeeAlso}
\begin{Examples}
\begin{ExampleCode}
  r.savings <- regr(sr ~ pop15 + pop75 + dpi + ddpi, data = LifeCycleSavings)
  plot(r.savings)

  data(d.blast)
  r.blast <-
       regr(log10(tremor)~location+log10(distance)+log10(charge),
            data=d.blast)
  plresx(r.blast, xplot=~.+no) \end{ExampleCode}
\end{Examples}

\HeaderA{predict.regr}{Prediction Methods for 'regr' Objects}{predict.regr}
\aliasA{predict.mlm}{predict.regr}{predict.mlm}
\aliasA{predict.polr}{predict.regr}{predict.polr}
\keyword{regression}{predict.regr}
\begin{Description}\relax
Calculates predicted values for \code{regr} objects.
The possible results depend on the class of the fitted model.
\end{Description}
\begin{Usage}
\begin{verbatim}
predict(object, newdata = NULL, se.fit = FALSE, scale = object$sigma,
interval = c("none", "confidence", "prediction"), level = 0.95,
type = NULL, terms = NULL, na.action = na.pass, ...)
\end{verbatim}
\end{Usage}
\begin{Arguments}
\begin{ldescription}
\item[\code{object}] Object of class \code{regr}
\item[\code{newdata}] An optional data frame in which to look for variables with
which to predict.  If omitted, the fitted values are used.
\item[\code{se.fit}] if TRUE, standard errors will be calculated if possible
\item[\code{scale}] Scale parameter for std.err. calculation
\item[\code{interval}] Type of interval requested
\item[\code{level}] Confidence level
\item[\code{type}] Type of prediction: response or model term\\
For glm or ordered regression, type \code{link} gives estimated values
of the linear predictor.
\item[\code{terms}] If \code{type="terms"}, which terms (default is all terms)
\item[\code{na.action}] function determining what should be done with missing values
in \code{newdata}.  The default is to insert \code{NA}.
\item[\code{...}] further arguments passed to specific methods
\end{ldescription}
\end{Arguments}
\begin{Details}\relax
\code{regr} is a "super class" which includes many specific model
classes such as "lm", "glm", "polr", ... .
\code{predict.regr} is a wrapper function that calls the specific methods
corresponding to the specific model class.
\end{Details}
\begin{Value}
vector of predictions, or matrix with columns \code{fit}, \code{lwr},
and \code{upr} if \code{interval} is set.

If \code{se.fit} is \code{TRUE}, a list with the
following components is returned:  

\begin{ldescription}
\item[\code{fit}] vector or matrix as above
\item[\code{se.fit}] standard error of predicted means
\item[\code{residual.scale}] residual standard deviations
\item[\code{df}] degrees of freedom for residual~Describe the value returned
\end{ldescription}
\end{Value}
\begin{Author}\relax
Werner A. Stahel, ETH Zurich
\end{Author}
\begin{SeeAlso}\relax
\code{\LinkA{predict.lm}{predict.lm}}, \code{\LinkA{residuals.polr}{residuals.polr}}
\end{SeeAlso}
\begin{Examples}
\begin{ExampleCode}
data(d.blast)
r.blast <- regr(log10(tremor)~location+log10(distance)+log10(charge),
            data=d.blast)
t.pr <- predict(r.blast)
showd(t.pr)

data(d.fossiles)
r.mregr <-
  regr(cbind(sAngle,lLength,rWidth)~SST.Mean+Salinity+lChlorophyll+region+N,
                data=d.fossiles)
t.pr <- predict(r.mregr)
showd(t.pr)
\end{ExampleCode}
\end{Examples}

\HeaderA{regr0-internal}{Internal regr0 objects}{regr0.Rdash.internal}
\aliasA{.Options}{regr0-internal}{.Options}
\aliasA{add1.default}{regr0-internal}{add1.default}
\aliasA{BR}{regr0-internal}{BR}
\aliasA{DB}{regr0-internal}{DB}
\aliasA{deviance.lm}{regr0-internal}{deviance.lm}
\aliasA{drop1.default}{regr0-internal}{drop1.default}
\aliasA{drop1.lm}{regr0-internal}{drop1.lm}
\aliasA{extractAIC.regr}{regr0-internal}{extractAIC.regr}
\aliasA{fitted.values.polr}{regr0-internal}{fitted.values.polr}
\aliasA{i.add1na}{regr0-internal}{i.add1na}
\aliasA{i.glm}{regr0-internal}{i.glm}
\aliasA{i.lm}{regr0-internal}{i.lm}
\aliasA{i.main}{regr0-internal}{i.main}
\aliasA{i.mlm}{regr0-internal}{i.mlm}
\aliasA{i.multinomial}{regr0-internal}{i.multinomial}
\aliasA{i.plotlars}{regr0-internal}{i.plotlars}
\aliasA{i.plotlws}{regr0-internal}{i.plotlws}
\aliasA{i.polr}{regr0-internal}{i.polr}
\aliasA{i.smooth}{regr0-internal}{i.smooth}
\aliasA{i.termtable}{regr0-internal}{i.termtable}
\aliasA{is.formula}{regr0-internal}{is.formula}
\aliasA{is.R}{regr0-internal}{is.R}
\aliasA{merge1}{regr0-internal}{merge1}
\aliasA{nna}{regr0-internal}{nna}
\aliasA{print.mregr}{regr0-internal}{print.mregr}
\aliasA{print.regr}{regr0-internal}{print.regr}
\aliasA{summary.mreg}{regr0-internal}{summary.mreg}
\aliasA{summary.regr}{regr0-internal}{summary.regr}
\aliasA{u.merge}{regr0-internal}{u.merge}
\aliasA{vif.regr}{regr0-internal}{vif.regr}
\keyword{internal}{regr0-internal}
\begin{Description}\relax
Internal regr0 objects.
\end{Description}
\begin{Details}\relax
These are not to be called by the user.
\end{Details}


\HeaderA{regr}{Fitting Regression Models}{regr}
\keyword{regression}{regr}
\begin{Description}\relax
'regr' fits regression models of various types: ordinary, robust,
generalized linear, multinomial, ordered response, multivariate, ... \bsl{}
It is a wrapper function which calls the respective S fitting
functions and yields an extensive result, to be used by the
respective print and plot methods.
\end{Description}
\begin{Usage}
\begin{verbatim}
regr(formula, data, tit = NULL, method = "lm", family = NA,
  init.reg = "f.ltsreg", subset = NULL, weights = NULL,
  na.action = nainf.exclude, model = TRUE, calcdisp = NULL,
  termtable = TRUE, vif = TRUE, ...)
\end{verbatim}
\end{Usage}
\begin{Arguments}
\begin{ldescription}
\item[\code{formula}] a symbolic description of the model to be fit. 
\item[\code{data}] data frame containing the variables in the model. 
\item[\code{tit}] title (becomes tit attribute of result) 
\item[\code{method}] S function to be called for fitting.
By default, \code{glm} is used if \code{family} is set, and
\code{lm} is used otherwise. 
\item[\code{family}] character string describing the type of model and the
fitting procedure. By default, \code{regr} will fit a model that is
suitable for the response variable, if possible.\bsl{}
Can be either
"gaussian" for ordinary regression, including multivariate response,
"binomial" for logistic regression,
"poisson"  for Poisson regression,
"multinomial" for multinomial regression,
"polr" for ordered response (cumulative logits) regression,
or a suitable argument for \code{glm}, i.e.: A
description of the error distribution and link
function to be used in the model. This can be a character string
naming a family function, a family function or the result of a call
to a family function.  (See 'family' for details of family functions.) 
\item[\code{init.reg}] function used to initialize robust methods 
\item[\code{subset}] an optional vector specifying a subset of observations to be
used in the fitting process. Names of variables in \code{data} can
be used to generate the vector. 
\item[\code{weights}] an optional vector of weights to be used for fitting. 
\item[\code{na.action}] a function which indicates what should happen when the data
contain 'NA's.  The default is set by the 'na.action' setting
of 'options', and is 'na.fail' if that is unset.  The
"factory-fresh" default is 'na.omit'.  Another possible value
is 'NULL', no action.  Value 'na.exclude' can be useful. 
\item[\code{model}] a logical value indicating whether the model frame should be
included as a component of the returned value. 
\item[\code{calcdisp}] a logical value indicating whether, for
\code{family=binomial} and \code{family=poisson}, dispersion
should be calculated \code{(TRUE)} or set to 1 \code{(FALSE)} 
\item[\code{termtable}] if \code{FALSE}, the \code{regr} type term table will
not be generated
\item[\code{vif}] a logical value indicating whether the collinearity
measure R2.j ahould be calculated 
\item[\code{...}] other argument to be passed to the fitting function 
\end{ldescription}
\end{Arguments}
\begin{Value}
\code{regr} returns a list object of class \code{regr} and secondary class as
produced by the fitting function. The components include generally
those of the results of the fitting function and its summary.
Additional components are described here in a draft version.
\begin{ldescription}
\item[\code{stres }] Standardized residuals
\item[\code{sigma }] estimated standard deviation for normal errors,\bsl{}
sqrt(dispersion) for \code{glm}
\item[\code{testcoef}] Table for testing terms both for single and mulitple
degree terms (continuous or binary explanatory variables and
factors)
\item[\code{allcoef}] All coefficients. Estimated effects of factors are
given for all their levels.
\item[\code{h}] leverage values
\item[\code{vartype}] types of the input variables (c for continuous,
b for binary, f for factor, o for ordered factor)
\item[\code{binfac}] levels of binary factors
\item[\code{fitfun}] R function that has been called for fitting the model
\end{ldescription}
\end{Value}
\begin{Author}\relax
Werner A. Stahel, Seminar for Statistics, ETH Zurich
\end{Author}
\begin{SeeAlso}\relax
\code{\LinkA{lm}{lm}}, \code{\LinkA{glm}{glm}}, \code{\LinkA{rlm}{rlm}},
\code{\LinkA{multinom}{multinom}}, \code{\LinkA{polr}{polr}},...
\end{SeeAlso}
\begin{Examples}
\begin{ExampleCode}
data(d.blast)
( r.blast <-
  regr(log10(tremor)~location+log10(distance)+log10(charge), data=d.blast) )
## Anorexia
data(anorexia, package="MASS")
r.anorexia <- regr(Postwt ~ Prewt + Treat + offset(Prewt),
                   data = anorexia)
## Annette Dobson (1990) "An Introduction to Generalized Linear Models".
     ## Page 9: Plant Weight Data.
ctl <- c(4.17,5.58,5.18,6.11,4.50,4.61,5.17,4.53,5.33,5.14)
trt <- c(4.81,4.17,4.41,3.59,5.87,3.83,6.03,4.89,4.32,4.69)
d.dob <- data.frame(group = gl(2,10,20, labels=c("Ctl","Trt")),
                    weight = c(ctl, trt))
(r.dob <- regr(weight ~ group, data=d.dob))

## multinomial regression
data(d.surveyenvir)
t.r <- regr(disturbance~age+education+location, data=d.surveyenvir)

## ordered regression
t.r <- regr(Sat ~ Infl + Type + Cont, weights = housing$Freq, data = housing)
plot(t.r)

## multivariate regression
data(d.fossiles)
r.mregr <-
  regr(cbind(sAngle,lLength,rWidth)~SST.Mean+Salinity+lChlorophyll+region+N,
                data=d.fossiles)
\end{ExampleCode}
\end{Examples}

\HeaderA{residuals.polr}{Residuals of a Binary or Ordered Regression}{residuals.polr}
\keyword{regression}{residuals.polr}
\begin{Description}\relax
Calculates quartiles and random numbers according to the
conditional distribution of residuals for the latent variable of a
binary or ordinal regression, given the observed response value.
See Details for an explanation.
\end{Description}
\begin{Usage}
\begin{verbatim}
residuals(object)
\end{verbatim}
\end{Usage}
\begin{Arguments}
\begin{ldescription}
\item[\code{object}] the result of \code{polr} or of
\code{glm(,family=binomial)} with binary data.
\end{ldescription}
\end{Arguments}
\begin{Details}\relax
For binary and ordinal regression, the regression models can be
described by introducing a latent response variable Z of which the
observed response Y is a classified version, and for which a linear
regression applies. The errors of this "latent regression" have a
logistic distribution. Given the linearly predicted value eta[i],
which is the fitted value for the latent variable, the residual for
Z[i] can therefore be assumed to have a logistic distribution.

This function calculates quantiles and random numbers according to the
conditional distribution of residuals for Z[i], given the observed
y[i].
\end{Details}
\begin{Value}
a data.frame with the variables 
\begin{ldescription}
\item[\code{median}] medians of the conditional distributions
\item[\code{lowq}] lower quartiles
\item[\code{uppq}] upper quartiles
\item[\code{random}] random numbers, drawn according to the conditional
distributions
\item[\code{fit}] linear predictor values
\item[\code{y}] observed response values
\end{ldescription}
\end{Value}
\begin{Author}\relax
Werner A. Stahel, ETH Zurich
\end{Author}
\begin{References}\relax
See http://stat.ethz.ch/~stahel/regression
\end{References}
\begin{SeeAlso}\relax
\code{\LinkA{plot.regr}{plot.regr}}
\end{SeeAlso}
\begin{Examples}
\begin{ExampleCode}
house.plr <- polr(Sat ~ Infl + Type + Cont, weights = Freq, data = housing)
house.resid <- residuals(house.plr)
\end{ExampleCode}
\end{Examples}

\HeaderA{robrange}{Robust Range of Data}{robrange}
\keyword{univar}{robrange}
\begin{Description}\relax
Determines a robust range of the data on the basis of the trimmed mean
and variance
\end{Description}
\begin{Usage}
\begin{verbatim}
robrange(data, trim = 0.2, fac = 3)
\end{verbatim}
\end{Usage}
\begin{Arguments}
\begin{ldescription}
\item[\code{data}] a vector of data. Missing values are dropped 
\item[\code{trim}] trimming proportion 
\item[\code{fac}] factor used for expanding the range, see Details 
\end{ldescription}
\end{Arguments}
\begin{Details}\relax
The function determines the trimmed mean \code{m} and then the "upper
trimmed mean" \code{s} of absolute deviations from m, multiplied by
\code{fac}. The robust minimum is then defined as \code{m-fac*s} or
\code{min(data)}, whichever is larger, and similarly for the maximum.
\end{Details}
\begin{Value}
The robust range.
\end{Value}
\begin{Author}\relax
Werner Stahel, ETH Zurich
\end{Author}
\begin{SeeAlso}\relax
\code{\LinkA{plcoord}{plcoord}}
\end{SeeAlso}
\begin{Examples}
\begin{ExampleCode}
  x <- c(rnorm(20),rnorm(3,5,20))
  robrange(x)
\end{ExampleCode}
\end{Examples}

\HeaderA{showd}{Show a Part of a Data.frame}{showd}
\keyword{utilities}{showd}
\keyword{print}{showd}
\begin{Description}\relax
Shows a part of the data.frame which allows for grasping the nature of
the data. The function is typically used to make sure that the data is
what was desired and to grasp the nature of the variables in the phase
of getting acquainted with the data.
\end{Description}
\begin{Usage}
\begin{verbatim}
showd(data, first = 3, nrow. = 4, ncol. = NULL, doc=options("doc")[[1]])
\end{verbatim}
\end{Usage}
\begin{Arguments}
\begin{ldescription}
\item[\code{data}] a data.frame (or a matrix)
\item[\code{first}] the first \code{first} rows will be shown and ...
\item[\code{nrow.}] a selection of \code{nrow.} rows will be shown in
addition. They will be selected with equal row number differences.
The last row is always included.
\item[\code{ncol.}] number of columns (variables) to be shown. The first and
last columns will also be included. If \code{ncol.} has more than
one element, it is used to identify the columns directly.
\item[\code{doc}] if TRUE or \code{>=1}, the \code{tit} attribute will be
printed if available, if \code{>=1}, any \code{doc} attribute will
be printed, too.
\end{ldescription}
\end{Arguments}
\begin{Value}
return invisibly the character vector containing the formatted data
\end{Value}
\begin{Author}\relax
Werner A. Stahel, ETH Zurich
\end{Author}
\begin{Examples}
\begin{ExampleCode}
showd(iris)
data(d.rehab)
showd(d.rehab, ncol=7, doc=TRUE)
\end{ExampleCode}
\end{Examples}

\HeaderA{simresiduals}{Simulate Residuals}{simresiduals}
\keyword{regression}{simresiduals}
\begin{Description}\relax
Simulates residuals for a given normal regression model
\end{Description}
\begin{Usage}
\begin{verbatim}
simresiduals(object, nrep, resgen=NULL)
\end{verbatim}
\end{Usage}
\begin{Arguments}
\begin{ldescription}
\item[\code{object}] result of fitting a regression
\item[\code{nrep}] number of replicates
\item[\code{resgen}] if a function, it is used to generate random residuals,
which will be multiplied by object\$sigma. If TRUE, \code{rnorm} will
be used. If NULL (default) the standardized residuals of
\code{object} will be randomly permuted
\end{ldescription}
\end{Arguments}
\begin{Details}\relax
The simulated residuals are obtained by replacing the response
variable by resampled standardized residuals of the fitted regression,
multiplied by the scale \code{object\$sigma}.
\end{Details}
\begin{Value}
A list consisting of
\begin{ldescription}
\item[\code{simres}] a matrix of which each column contains an set of
simulated residuals
\item[\code{simstres}] corresponding standardized residuals
\end{ldescription}
\end{Value}
\begin{Author}\relax
Werner A. Stahel, ETH Zurich
\end{Author}
\begin{Examples}
\begin{ExampleCode}
"will follow"
\end{ExampleCode}
\end{Examples}

\HeaderA{stamp}{Add an Identification Line to a Plot}{stamp}
\keyword{utilities}{stamp}
\keyword{misc}{stamp}
\begin{Description}\relax
A line is added to the current plot in the lower right corner
that contains project information and date.
\end{Description}
\begin{Usage}
\begin{verbatim}
stamp(sure = TRUE, outer.margin = NULL,
  project = options("project")[[1]], step=options("step")[[1]],
  stamp=options("stamp")[[1]], ...)
\end{verbatim}
\end{Usage}
\begin{Arguments}
\begin{ldescription}
\item[\code{sure}] if FALSE, the stamp will only be added if
\code{options("stamp")[[1]]>0} 
\item[\code{outer.margin}] if TRUE, the stamp is put to the outer margin of
the plot. This is the default if the plot is currently split into panels.
\item[\code{project, step}] character string describing the project and the step of
analysis.
\item[\code{stamp}] controls default action, see details 
\item[\code{...}] arguments passed to \code{mtext}
\end{ldescription}
\end{Arguments}
\begin{Details}\relax
The function is used to document plots produced during a data
analysis. It is called by all plotting functions of this package.
For getting final presentation versions of the plots, the stamp can be
suppressed by changing the default by calling \code{options(stamp=0)}.

In more detail:  If \code{stamp==0} (or \code{options("stamp")==0})
the function will only do its thing if \code{sure==TRUE}.

If \code{stamp==2}, it will certainly do it.

If \code{stamp==1} and \code{sure==FALSE}, the stamp is added when a
plot page is complete.
\end{Details}
\begin{Value}
invisibly returns the string that is added to the plot
\end{Value}
\begin{Author}\relax
Werner A. Stahel, ETH Zurich
\end{Author}
\begin{Examples}
\begin{ExampleCode}
options(project="Example A",  step="regression analysis")
plot(1:10)
stamp()
\end{ExampleCode}
\end{Examples}

\HeaderA{sumna}{Count NAs}{sumna}
\keyword{NA}{sumna}
\begin{Description}\relax
Count the missing or non-finite values for each column of a matrix or
data.frame
\end{Description}
\begin{Usage}
\begin{verbatim}
sumna(object, inf = TRUE)
\end{verbatim}
\end{Usage}
\begin{Arguments}
\begin{ldescription}
\item[\code{object}] a vector, matrix, or data.frame
\item[\code{inf}] if TRUE, Inf and NaN values are counted along with NAs
\end{ldescription}
\end{Arguments}
\begin{Value}
numerical vector containing the missing value counts for each column
\end{Value}
\begin{Note}\relax
This is a simple shortcut for \code{apply(is.na(object),2,sum)}
or \code{apply(!is.finite(object),2,sum)}
\end{Note}
\begin{Author}\relax
Werner A. Stahel, ETH Zurich
\end{Author}
\begin{SeeAlso}\relax
\code{\LinkA{is.na}{is.na}}, \code{\LinkA{is.finite}{is.finite}}
\end{SeeAlso}
\begin{Examples}
\begin{ExampleCode}
t.d <- data.frame(V1=c(1,2,NA,4), V2=c(11,12,13,Inf), V3=c(21,NA,23,Inf))
sumna(t.d)
\end{ExampleCode}
\end{Examples}

\HeaderA{u.gmeth}{Get an S3 Method of a Generic Function}{u.gmeth}
\keyword{utilities}{u.gmeth}
\begin{Description}\relax
Gets the method of a generic S3 function appying to a particular S3 class
\end{Description}
\begin{Usage}
\begin{verbatim}
u.gmeth(fn, mt)
\end{verbatim}
\end{Usage}
\begin{Arguments}
\begin{ldescription}
\item[\code{fn}] generic function name, need not be quoted
\item[\code{mt}] class name, need not be quoted
\end{ldescription}
\end{Arguments}
\begin{Value}
the function that defines the method of the generic function
\end{Value}
\begin{Note}\relax
This is a simple shortcut for
\code{getS3method(as.character(substitute(fn)),as.character(substitute(mt)))}
\end{Note}
\begin{Author}\relax
Werner A. Stahel, ETH Zurich
\end{Author}
\begin{SeeAlso}\relax
~~objects to See Also as \code{\LinkA{help}{help}}, ~~~
\end{SeeAlso}
\begin{Examples}
\begin{ExampleCode}
u.gmeth(drop1,lm)
\end{ExampleCode}
\end{Examples}

\HeaderA{warn}{List Warnings}{warn}
\keyword{utilities}{warn}
\begin{Description}\relax
Gives a List of Warnings
\end{Description}
\begin{Usage}
\begin{verbatim}
warn()
\end{verbatim}
\end{Usage}
\begin{Details}\relax
This function simplyfies the output of \code{\LinkA{warnings}{warnings}} if there
are several identical warnings, by counting their occurence
\end{Details}
\begin{Value}
the table of warnings
\end{Value}
\begin{Author}\relax
Werner A. Stahel, ETH Zurich
\end{Author}
\begin{SeeAlso}\relax
\code{\LinkA{warnings}{warnings}}
\end{SeeAlso}
\begin{Examples}
\begin{ExampleCode}
##  not to be run as an example()
##  for (i in 3:6)
##    m <- matrix(1:7, 3,i)
##  warn()
\end{ExampleCode}
\end{Examples}

\end{document}
